{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will help you train a raw Point-Cloud GAN.\n",
    "\n",
    "(Assumes latent_3d_points is in the PYTHONPATH and that a trained AE model exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/hq45/pointnet', '/home/hq45/pointnet/latent_3d_points_py3/notebooks', '/home/hq45/pointnet/latent_3d_points', '/home/hq45/anaconda3/envs/condavenv/lib/python37.zip', '/home/hq45/anaconda3/envs/condavenv/lib/python3.7', '/home/hq45/anaconda3/envs/condavenv/lib/python3.7/lib-dynload', '', '/home/hq45/.local/lib/python3.7/site-packages', '/home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages', '/home/hq45/.local/lib/python3.7/site-packages/IPython/extensions', '/home/hq45/.ipython']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hq45/anaconda3/envs/condavenv/lib/python3.7/site-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'external'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cd71839d70a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/home/hq45/pointnet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlatent_3d_points_py3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfiguration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mConf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlatent_3d_points_py3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_net\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMODEL_SAVER_ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pointnet/latent_3d_points_py3/src/autoencoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtflearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0min_out\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpickle_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0mgeneral_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapply_augmentations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterate_in_chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0mneural_net\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeural_Net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_SAVER_ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pointnet/latent_3d_points_py3/src/in_out.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0mgeneral_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrand_rotation_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mexternal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_plyfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplyfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlyElement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPlyData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m snc_synth_id_to_category = {\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'external'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path as osp\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.insert(0, \"/home/hq45/pointnet\")\n",
    "\n",
    "from latent_3d_points_py3.src.autoencoder import Configuration as Conf\n",
    "from latent_3d_points_py3.src.neural_net import MODEL_SAVER_ID\n",
    "\n",
    "from latent_3d_points_py3.src.in_out import snc_category_to_synth_id, create_dir, PointCloudDataSet, \\\n",
    "                                        load_all_point_clouds_under_folder\n",
    "\n",
    "from latent_3d_points_py3.src.general_utils import plot_3d_point_cloud\n",
    "from latent_3d_points_py3.src.tf_utils import reset_tf_graph\n",
    "\n",
    "from latent_3d_points_py3.src.vanilla_gan import Vanilla_GAN\n",
    "from latent_3d_points_py3.src.w_gan_gp import W_GAN_GP\n",
    "from latent_3d_points_py3.src.generators_discriminators import point_cloud_generator,\\\n",
    "mlp_discriminator, leaky_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to save Neural-Net check-points etc.\n",
    "top_out_dir = '../data/'          \n",
    "\n",
    "# Top-dir of where point-clouds are stored.\n",
    "top_in_dir = '../data/shape_net_core_uniform_samples_2048/'\n",
    "\n",
    "experiment_name = 'raw_gan_with_w_gan_loss'\n",
    "\n",
    "n_pc_points = 2048                # Number of points per model.\n",
    "class_name = input('Give me the class name (e.g. \"chair\"): ').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load point-clouds.\n",
    "syn_id = snc_category_to_synth_id()[class_name]\n",
    "class_dir = osp.join(top_in_dir , syn_id)\n",
    "all_pc_data = load_all_point_clouds_under_folder(class_dir, n_threads=8, file_ending='.ply', verbose=True)\n",
    "print('Shape of DATA =', all_pc_data.point_clouds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set GAN parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_wgan = True     # Wasserstein with gradient penalty, or not?\n",
    "n_epochs = 10       # Epochs to train.\n",
    "\n",
    "plot_train_curve = True\n",
    "save_gan_model = True\n",
    "saver_step = np.hstack([np.array([1, 5, 10]), np.arange(50, n_epochs + 1, 50)])\n",
    "\n",
    "# If true, every 'saver_step' epochs we produce & save synthetic pointclouds.\n",
    "save_synthetic_samples = True\n",
    "# How many synthetic samples to produce at each save step.\n",
    "n_syn_samples = all_pc_data.num_examples\n",
    "\n",
    "# Optimization parameters\n",
    "init_lr = 0.0001\n",
    "batch_size = 50\n",
    "noise_params = {'mu':0, 'sigma': 0.2}\n",
    "noise_dim = 128\n",
    "beta = 0.5 # ADAM's momentum.\n",
    "\n",
    "n_out = [n_pc_points, 3] # Dimensionality of generated samples.\n",
    "\n",
    "\n",
    "discriminator = mlp_discriminator\n",
    "generator = point_cloud_generator\n",
    "\n",
    "if save_synthetic_samples:\n",
    "    synthetic_data_out_dir = osp.join(top_out_dir, 'OUT/synthetic_samples/', experiment_name)\n",
    "    create_dir(synthetic_data_out_dir)\n",
    "\n",
    "if save_gan_model:\n",
    "    train_dir = osp.join(top_out_dir, 'OUT/raw_gan', experiment_name)\n",
    "    create_dir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reset_tf_graph()\n",
    "\n",
    "if use_wgan:\n",
    "    lam = 10\n",
    "    disc_kwargs = {'b_norm': False}\n",
    "    gan = W_GAN_GP(experiment_name, init_lr, lam, n_out, noise_dim,\n",
    "                    discriminator, generator,\n",
    "                    disc_kwargs=disc_kwargs, beta=beta)\n",
    "    \n",
    "else:    \n",
    "    leak = 0.2\n",
    "    disc_kwargs = {'non_linearity': leaky_relu(leak), 'b_norm': False}\n",
    "    gan = Vanilla_GAN(experiment_name, init_lr, n_out, noise_dim,\n",
    "                      discriminator, generator, beta=beta, disc_kwargs=disc_kwargs)\n",
    "\n",
    "accum_syn_data = []\n",
    "train_stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the GAN.\n",
    "for _ in range(n_epochs):\n",
    "    loss, duration = gan._single_epoch_train(all_pc_data, batch_size, noise_params)\n",
    "    epoch = int(gan.sess.run(gan.increment_epoch))\n",
    "    print(epoch, loss)\n",
    "\n",
    "    if save_gan_model and epoch in saver_step:\n",
    "        checkpoint_path = osp.join(train_dir, MODEL_SAVER_ID)\n",
    "        gan.saver.save(gan.sess, checkpoint_path, global_step=gan.epoch)\n",
    "\n",
    "    if save_synthetic_samples and epoch in saver_step:\n",
    "        syn_data = gan.generate(n_syn_samples, noise_params)\n",
    "        np.savez(osp.join(synthetic_data_out_dir, 'epoch_' + str(epoch)), syn_data)\n",
    "        for k in range(3):  # plot three (synthetic) random examples.\n",
    "            plot_3d_point_cloud(syn_data[k][:, 0], syn_data[k][:, 1], syn_data[k][:, 2],\n",
    "                               in_u_sphere=True)\n",
    "\n",
    "    train_stats.append((epoch, ) + loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_train_curve:\n",
    "    x = range(len(train_stats))\n",
    "    d_loss = [t[1] for t in train_stats]\n",
    "    g_loss = [t[2] for t in train_stats]\n",
    "    plt.plot(x, d_loss, '--')\n",
    "    plt.plot(x, g_loss)\n",
    "    plt.title('GAN training. (%s)' %(class_name))\n",
    "    plt.legend(['Discriminator', 'Generator'], loc=0)\n",
    "    \n",
    "    plt.tick_params(axis='x', which='both', bottom='off', top='off')\n",
    "    plt.tick_params(axis='y', which='both', left='off', right='off')\n",
    "    \n",
    "    plt.xlabel('Epochs.') \n",
    "    plt.ylabel('Loss.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
